{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/harrisonchase/workplace/kensho-learn/kml/lib/python2.7/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n",
      "/Users/harrisonchase/workplace/kensho-learn/kml/lib/python2.7/site-packages/sklearn/grid_search.py:43: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. This module will be removed in 0.20.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "from time import time\n",
    "from operator import itemgetter\n",
    "from scipy.stats import randint as sp_randint\n",
    "\n",
    "from sklearn.grid_search import GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import RidgeCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bigdata = pd.read_csv(\"data/RegularSeasonDetailedResults.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get rate statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Score Dif\n",
    "bigdata['dif'] = bigdata.Wscore-bigdata.Lscore\n",
    "# Pace\n",
    "bigdata['pace'] = (bigdata.Wfga+bigdata.Lfga - bigdata.Wor - bigdata.Lor+bigdata.Wto+bigdata.Lto+0.475*(bigdata.Wfta + bigdata.Lfta))/2\n",
    "# Offensive (and by the converse, defensive) rebounding percentage\n",
    "bigdata['Worp'] = bigdata.Wor/(bigdata.Ldr+bigdata.Wor)\n",
    "bigdata['Lorp'] = bigdata.Lor/(bigdata.Wdr+bigdata.Lor)\n",
    "# Turnover percentage\n",
    "bigdata['Wtop'] = bigdata.Wto/bigdata.pace\n",
    "bigdata['Ltop'] = bigdata.Lto/bigdata.pace\n",
    "# Assist percentage\n",
    "bigdata['Wastp'] = bigdata.Wast/bigdata.Wfgm\n",
    "bigdata['Lastp'] = bigdata.Last/bigdata.Lfgm\n",
    "# Shooting percentage\n",
    "bigdata['Wfgp'] = bigdata.Wfgm/bigdata.Wfga\n",
    "bigdata['Lfgp'] = bigdata.Lfgm/bigdata.Lfga\n",
    "# 3 pt percentage\n",
    "bigdata['Wfg3p'] = bigdata.Wfgm3/bigdata.Wfga3\n",
    "bigdata['Lfg3p'] = bigdata.Lfgm3/bigdata.Lfga3\n",
    "# Free throw shooting percentage (perhaps not needed?)\n",
    "bigdata['Wftp'] = bigdata.Wftm/bigdata.Wfta\n",
    "bigdata['Lftp'] = bigdata.Lftm/bigdata.Lfta\n",
    "# Steal percentage\n",
    "bigdata['Wstlp'] = bigdata.Wstl/bigdata.pace\n",
    "bigdata['Lstlp'] = bigdata.Lstl/bigdata.pace\n",
    "# Block percentage\n",
    "bigdata['Wblkp'] = bigdata.Wblk/bigdata.pace\n",
    "bigdata['Lblkp'] = bigdata.Lblk/bigdata.pace\n",
    "# 3 Point Rate\n",
    "bigdata['W3pr'] = bigdata.Wfga3/bigdata.Wfga\n",
    "bigdata['L3pr'] = bigdata.Lfga3/bigdata.Lfga\n",
    "# Free throw Rate\n",
    "bigdata['Wftr'] = bigdata.Wfta/bigdata.Wfga\n",
    "bigdata['Lftr'] = bigdata.Lfta/bigdata.Lfga\n",
    "# Offensive and Defensive overall\n",
    "bigdata['Wor'] = bigdata.Wscore/bigdata.pace\n",
    "bigdata['Lor'] = bigdata.Lscore/bigdata.pace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# by construction will get both offensive and defensive values\n",
    "STATS_TO_GET = [\n",
    "    'or', # offensive rating\n",
    "    'orp', # offensive rebounding percentage\n",
    "    'astp', # assist percentage\n",
    "    'fgp', # field goal shooting percantage\n",
    "    'fg3p', # 3 pt field goal shooting percentage\n",
    "    'ftp', # free throw percentage\n",
    "    'stlp', # steal percentage\n",
    "    'blkp', # block percentage\n",
    "    '3pr', # 3 point rate\n",
    "    'ftr', # free throw rate\n",
    "    'top' # turnover percentage\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seperate_off_and_def(series):\n",
    "    off_index = [x for x in series.index if '_o' in x]\n",
    "    def_index = [x for x in series.index if '_d' in x]\n",
    "    if len(off_index) == 0:\n",
    "        return series.to_frame()\n",
    "    off_stat = series.loc[off_index]\n",
    "    def_stat = series.loc[def_index]\n",
    "    off_stat.index = [x.replace('_o','') for x in off_stat.index]\n",
    "    def_stat.index = [x.replace('_d','') for x in def_stat.index]\n",
    "    return pd.concat([off_stat.to_frame().add_suffix('_o'),\n",
    "                      def_stat.to_frame().add_suffix('_d')], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_stat_series(xdf, ydf, name):\n",
    "    isnull_index = ydf[ydf.isnull()].index\n",
    "    ydf = ydf.drop(isnull_index)\n",
    "    xdf = xdf.drop(isnull_index)\n",
    "    model = RidgeCV(alphas=[float(x)/20 for x in range(1,100)])\n",
    "    model.fit(xdf,ydf)\n",
    "    index = [str(x) for x in xdf.columns]\n",
    "    return seperate_off_and_def(pd.Series(model.coef_, index=index, name=name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_all_stats_for_a_year(df, year):\n",
    "    data_train = df[lambda x: x.Season==year]\n",
    "    Wteam_dummies =pd.get_dummies(data_train.Wteam)\n",
    "    Lteam_dummies = pd.get_dummies(data_train.Lteam)\n",
    "    for col in Wteam_dummies.columns.difference(Lteam_dummies.columns):\n",
    "        Lteam_dummies[col] = 0\n",
    "    for col in Lteam_dummies.columns.difference(Wteam_dummies.columns):\n",
    "        Wteam_dummies[col] = 0\n",
    "    abs_df = pd.concat([Wteam_dummies + Lteam_dummies], axis=1).reset_index(drop=True)\n",
    "    first_df = pd.concat([Wteam_dummies.add_suffix('_o'), -1*Lteam_dummies.add_suffix('_d')], axis=1).reset_index(drop=True)\n",
    "    second_df = pd.concat([-1*Wteam_dummies.add_suffix('_d'), Lteam_dummies.add_suffix('_o')], axis=1).reset_index(drop=True)\n",
    "    home_vector = pd.concat([(data_train['Wloc'] == 'H').astype(int),(data_train['Wloc'] == 'H').astype(int)]).reset_index(drop=True)\n",
    "    xdf = pd.concat([pd.concat([first_df, second_df]).reset_index(drop=True), home_vector], axis=1).fillna(0)\n",
    "    list_of_stat_rankings = []\n",
    "    for stat in ['pace']:\n",
    "        ydf = data_train[stat].reset_index(drop=True)\n",
    "        list_of_stat_rankings.append(get_stat_series(abs_df, ydf, stat))\n",
    "    for stat in STATS_TO_GET:\n",
    "        ydf = pd.concat([data_train['W{}'.format(stat)], data_train['L{}'.format(stat)]]).reset_index(drop=True)\n",
    "        list_of_stat_rankings.append(get_stat_series(xdf, ydf, stat))\n",
    "    all_stats = pd.concat(list_of_stat_rankings, axis=1)\n",
    "    all_stats.index.name='team'\n",
    "    return all_stats.reset_index().assign(year=year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cacluating stats for year 2003\n",
      "Cacluating stats for year 2004\n",
      "Cacluating stats for year 2005\n",
      "Cacluating stats for year 2006\n",
      "Cacluating stats for year 2007\n",
      "Cacluating stats for year 2008\n",
      "Cacluating stats for year 2009\n",
      "Cacluating stats for year 2010\n",
      "Cacluating stats for year 2011\n",
      "Cacluating stats for year 2012\n",
      "Cacluating stats for year 2013\n",
      "Cacluating stats for year 2014\n",
      "Cacluating stats for year 2015\n",
      "Cacluating stats for year 2016\n",
      "Cacluating stats for year 2017\n"
     ]
    }
   ],
   "source": [
    "\n",
    "stat_database = []\n",
    "for year in range(min(bigdata.Season),max(bigdata.Season)+1):\n",
    "    print 'Cacluating stats for year {}'.format(year)\n",
    "    stat_database.append(get_all_stats_for_a_year(bigdata, year))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_stats = pd.concat(stat_database)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5130, 25)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_stats.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_stats.to_msgpack('all_stats.mp')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
